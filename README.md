# Gesture_recognition
Models for Palm detection and tracking
## Run  palm detection and hand landmark model
<table class="tfo-notebook-buttons" align="left">
  <td>
    <a target="_blank" href="https://colab.research.google.com/github/usefulsensors/gesture_recognition/blob/main/hand_model.ipynb"><img src="https://www.tensorflow.org/images/colab_logo_32px.png" />Google Colaboratory</a>
  </td>
</table>
*Estimated Conversion Time: ~1 Mins.*

##   

## Run quantized palm detection model(192x192X3)
<table class="tfo-notebook-buttons" align="left">
  <td>
    <a target="_blank" href="https://colab.research.google.com/github/usefulsensors/gesture_recognition/blob/main/Palm_Detection_int8_model_and_Tracking.ipynb"><img src="https://www.tensorflow.org/images/colab_logo_32px.png" />Google Colaboratory</a>
  </td>
</table>
*Estimated Conversion Time: ~1 Mins.*

##   

# TensorFlow Lite Gesture Classification model(model_metadata.tflite)

https://github.com/tensorflow/examples/tree/master/lite/examples/gesture_classification/android
##   
